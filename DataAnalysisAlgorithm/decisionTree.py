import numpy as np

# 信息熵，表示信息的不确定度
# Entropy(t)=-∑p(i|t)log2p(i|t)
# 例如集合1:5次去打篮球，1次不去；集合2:3次去打篮球，3次不打

E1 = -5 / 6 * np.log2(5 / 6) - 1 / 6 * np.log2(1 / 6)
E2 = -3 / 6 * np.log2(3 / 6) - 3 / 6 * np.log2(3 / 6)
print(E1, E2)  # 0.6500224216483541 1.0
# 信息熵越大，纯度越低

# ID3，计算信息增益
# Gain(D,a)=Entropy(D)-∑|Di|/|D|Entropy(Di)
# 公式中 D 是父亲节点，Di 是子节点，Gain(D,a) 中的 a 作为 D 节点的属性选择

# 3打4不打
# D1(天气 = 晴天)={1-,2-,6+}
# D2(天气 = 阴天)={3+,7-}
# D3(天气 = 小雨)={4+,5-}

E_D1 = -2/3 * np.log2(2/3) - 1/3 * np.log2(1/3)
E_D2 = -1/2 * np.log2(1/2) - 1/2 * np.log2(1/2)
E_D3 = -1/2 * np.log2(1/2) - 1/2 * np.log2(1/2)
print(E_D1, E_D2, E_D3)  # 0.9182958340544896 1.0 1.0
E_D = -3/7 * np.log2(3/7) - 4/7 * np.log2(4/7)
G_sunny = E_D - (3/7*E_D1+2/7*E_D2+2/7*E_D3)
print(G_sunny)




