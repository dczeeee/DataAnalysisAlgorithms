import numpy as np

# 信息熵，表示信息的不确定度
# Entropy(t)=-∑p(i|t)log2p(i|t)
# 例如集合1:5次去打篮球，1次不去；集合2:3次去打篮球，3次不打

E1 = -5/6 * np.log2(5/6) - 1/6 * np.log2(1/6)
E2 = -3/6 * np.log2(3/6) - 3/6 * np.log2(3/6)
print(E1, E2)   # 0.6500224216483541 1.0
# 信息熵越大，纯度越低





